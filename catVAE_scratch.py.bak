import gdown
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import pyro
import pyro.distributions as dist
import scanpy as sc
import seaborn as sns
import time
import torch
import torch.utils.data
import torchvision.utils as vutils
import umap
from abc import abstractmethod
from anndata.experimental.pytorch import AnnLoader
from importlib import reload
from math import pi, sin, cos, sqrt, log
from pyro.infer import SVI, JitTrace_ELBO, Trace_ELBO, TraceGraph_ELBO
from pyro.optim import Adam
from sklearn.cluster import KMeans
from sklearn.metrics.cluster import normalized_mutual_info_score
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from toolz import partial, curry
from torch import nn, optim, distributions, Tensor
from torch.nn.functional import one_hot
from torchvision import datasets, transforms, models
from torchvision.utils import save_image, make_grid
from typing import Callable, Iterator, Union, Optional, TypeVar
from typing import List, Set, Dict, Tuple
from typing import Mapping, MutableMapping, Sequence, Iterable
from typing import Union, Any, cast, IO, TextIO

# my own sauce
from my_torch_utils import denorm, normalize, mixedGaussianCircular
from my_torch_utils import fclayer, init_weights, buildNetwork
from my_torch_utils import fnorm, replicate, logNorm, log_gaussian_prob
from my_torch_utils import plot_images, save_reconstructs, save_random_reconstructs
from my_torch_utils import scsimDataset
import my_torch_utils as ut

print(torch.cuda.is_available())

from importlib import reload
#from catVAE import *
import catVAE as M


transform = transforms.Compose([
    transforms.Resize((32,32)),
    transforms.ToTensor(),
    #normalize,
    ])
test_loader = torch.utils.data.DataLoader(
   dataset=datasets.MNIST(
       root='data/',
       train=False,
       download=True,
       transform=transform,
       ),
   batch_size=128,
   shuffle=True,
)
train_loader = torch.utils.data.DataLoader(
   dataset=datasets.MNIST(
       root='data/',
       train=True,
       download=True,
       transform=transform,
       ),
   batch_size=128,
   shuffle=True,
)


test_data = test_loader.dataset.data.float()/255
test_labels = test_loader.dataset.targets
train_data = train_loader.dataset.data.float()/255
train_labels = train_loader.dataset.targets

model = M.VAE(28**2, 20, 1024)


x, y = test_loader.__iter__().__next__()

x = x.to(0)
model.to(0)

model(x)

model.fit(train_loader, )

x,y = iter(test_loader).next()

xhat = model.generate(x)
xhat = xhat.reshape(x.shape)

plot_images(x)

plot_images(xhat)

fig, axs = plt.subplots(1,2)

grid_img1 = make_grid(x, nrow=16).permute(1, 2, 0)
grid_img2 = make_grid(xhat, nrow=16).permute(1, 2, 0)

axs[0].imshow(grid_img1)
axs[1].imshow(grid_img2)


z_locs, _  = model.encode(test_data)

ut.plot_tsne(z_locs, test_labels, "mnist_vae_tsne")

latent = z_locs.detach().cpu()

reducer = umap.UMAP(random_state=42)
reducer.fit(X=latent)
embedding = reducer.transform(latent)

plt.scatter(embedding[:,0], embedding[:,1], c=test_labels, cmap='Spectral', s=5)
plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))
plt.title('UMAP projection of the Digits dataset', fontsize=24);


class Foo():
    def __init__(self, a):
        self.a = a
        return

class Bar(Foo):
    def __init__(self, a, b):
        super().__init__(a)
        self.b = b
        return

b = Bar(1,2)
print(b.a, b.b)





  
import pytorch_lightning as pl
pl.seed_everything(1234)
from torch import nn
import torch
from pl_bolts.models.autoencoders.components import (
    resnet18_decoder,
    resnet18_encoder,
)
from pl_bolts.datamodules import CIFAR10DataModule, ImagenetDataModule


class VAE(pl.LightningModule):
    # https://github.com/williamFalcon/pytorch-lightning-vae/blob/main/vae.py
    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32):
        super().__init__()

        self.save_hyperparameters()

        # encoder, decoder
        #self.encoder = resnet18_encoder(False, False)
        self.nin = nin = input_height**2
        self.nh = nh = enc_out_dim
        self.nz = nz = latent_dim
        self.encoder = buildNetwork([nin, nh, nh], activation=nn.LeakyReLU(),)
        self.decoder = buildNetwork([nz, nh, nh], activation=nn.LeakyReLU(),)
        self.decoder.add_module('last_fc', nn.Linear(nh, nin))

        # distribution parameters
        self.fc_mu = nn.Linear(nh, nz)
        self.fc_var = nn.Linear(nh, nz)

        # for the gaussian likelihood
        self.log_scale = nn.Parameter(torch.Tensor([0.0]))

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=1e-4)

    def gaussian_likelihood(self, x_hat, logscale, x):
        scale = torch.exp(logscale)
        mean = x_hat
        dist = torch.distributions.Normal(mean, scale)

        # measure prob of seeing image under p(x|z)
        log_pxz = dist.log_prob(x)
        return log_pxz.sum(dim=(1, 2, 3))

    def kl_divergence(self, z, mu, std):
        # --------------------------
        # Monte carlo KL divergence
        # --------------------------
        # 1. define the first two probabilities (in this case Normal for both)
        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))
        q = torch.distributions.Normal(mu, std)

        # 2. get the probabilities from the equation
        log_qzx = q.log_prob(z)
        log_pz = p.log_prob(z)

        # kl
        kl = (log_qzx - log_pz)
        kl = kl.sum(-1)
        return kl

    def training_step(self, batch, batch_idx):
        x, _ = batch

        # encode x to get the mu and variance parameters
        x_encoded = self.encoder(x)
        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)

        # sample z from q
        std = torch.exp(log_var / 2)
        q = torch.distributions.Normal(mu, std)
        z = q.rsample()

        # decoded
        x_hat = self.decoder(z)

        # reconstruction loss
        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)

        # kl
        kl = self.kl_divergence(z, mu, std)

        # elbo
        elbo = (kl - recon_loss)
        elbo = elbo.mean()

        self.log_dict({
            'elbo': elbo,
            'kl': kl.mean(),
            'recon_loss': recon_loss.mean(),
            'reconstruction': recon_loss.mean(),
            'kl': kl.mean(),
        })

        return elbo

    def fit(self,
            train_loader : torch.utils.data.DataLoader,
            num_epochs=10,
            lr=1e-3,
            device : str = "cuda:0",) -> None:
        self.to(device)
        optimizer = optim.Adam(self.parameters(), lr=lr)
        for epoch in range(10):
            for idx, (data, labels) in enumerate(train_loader):
                self.train()
                self.requires_grad_(True)
                optimizer.zero_grad()
                #x = data.flatten(1).to(device)
                x = torch.cat((data, data, data), dim=1)
                elbo = self.training_step((x, labels), idx)
                elbo.backward()
                optimizer.step()
                if idx % 300 == 0:
                    print("loss = ",
                            elbo.item(),
                            )
        self.cpu()
        optimizer = None
        print('done training')
        return None


model = VAE(512, 256, 28)

model = VAE()

model.encoder(x)

model.fit(train_loader)
